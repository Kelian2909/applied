

> Pr√©diction de la r√©admission hospitali√®re de patients diab√©tiques √† partir de donn√©es cliniques (UCI Machine Learning Repository)



## Description du projet

Ce projet s‚Äôappuie sur le jeu de donn√©es **[Diabetes 130-US hospitals for years 1999‚Äì2008](https://archive.ics.uci.edu/dataset/296/diabetes+130+us+hospitals+for+years+1999+2008)** publi√© par l‚ÄôUCI Machine Learning Repository.

L‚Äôobjectif est de **pr√©dire la probabilit√© de r√©admission d‚Äôun patient diab√©tique dans les 30 jours** suivant une hospitalisation, √† partir d‚Äôinformations d√©mographiques, m√©dicales et administratives.



## Objectifs

- Comprendre les **facteurs associ√©s √† la r√©admission** hospitali√®re des patients diab√©tiques.  
- .....
- .....




##  √âtapes du projet

## 1. Nettoyage et pr√©traitement

- Remplacement des valeurs manquantes (`"?"`) par `NaN` puis suppression ou imputation.
- Suppression des colonnes inutilisables ou constantes (`weight`, `payer_code`, `examide`, etc.).
- Encodage ordinal des variables de m√©dicaments (`"No" ‚Üí 0`, `"Steady" ‚Üí 1`, etc.).
- D√©finition des types de variables :
  - `num_cols` ‚Üí variables num√©riques √† standardiser (`StandardScaler`)
  - `ohe_cols` ‚Üí variables cat√©gorielles √† encoder (`OneHotEncoder`)
  - `other_cols` ‚Üí variables d√©j√† num√©riques
- Construction d‚Äôun pipeline (`ColumnTransformer`) combinant toutes les transformations.
- Cr√©ation de la variable cible binaire : `y = 1 si readmitted == "<30", sinon 0`.



## 2. S√©lection de variables

### 2.1. D√©termination du nombre optimal de variables par cross validation

Avant de proc√©der √† la s√©lection, il est essentiel de d√©terminer **combien de variables** il est pertinent de conserver.  
Pour cela, une **cross-validation** a √©t√© r√©alis√©e √† l‚Äôaide d‚Äôun mod√®le de **r√©gression logistique**.

Le principe consiste √† :
- S√©lectionner un nombre de variables `k` selon un crit√®re donn√©,
- √âvaluer la performance du mod√®le (AUC) via une **Stratified K-Fold Cross-Validation**,
- R√©p√©ter l‚Äôop√©ration pour diff√©rentes valeurs de `k`,
- Retenir le **nombre minimal de variables** donnant la **meilleure performance moyenne**.

Cette √©tape permet d‚Äô√©viter la **sur-s√©lection** tout en maximisant la **capacit√© pr√©dictive** du mod√®le final.  
C‚Äôest une approche empirique, mais robuste, qui garantit un bon compromis entre **complexit√©** et **performance**.



### 2.2. M√©thode 1 ‚Äî Information Mutuelle (IM)

L‚Äô**information mutuelle** mesure la **d√©pendance statistique** entre une variable explicative `X` et la cible `Y`.  
Elle indique combien d‚Äôinformation sur `Y` est contenue dans `X`.  
Si `X` et `Y` sont ind√©pendantes, elle est nulle.

Contrairement √† la corr√©lation lin√©aire (Pearson), l‚Äôinformation mutuelle capte **toutes les formes de d√©pendance** ‚Äî lin√©aires ou non lin√©aires.

`I(X;Y) = Œ£‚Çì,·µß p(x,y) * log( p(x,y) / [p(x) * p(y)] )`

- `p(x, y)` : probabilit√© jointe  
- `p(x)` et `p(y)` : probabilit√©s marginales  
- `I(X;Y) ‚â• 0`, et `I(X;Y) = 0` si ind√©pendance totale

L‚ÄôIM est une **m√©thode de type filtre** :  
chaque variable est √©valu√©e ind√©pendamment du mod√®le, ce qui la rend rapide et g√©n√©rique.  
Elle permet d‚Äôidentifier les variables **informativement pertinentes**, sans a priori sur la nature de la relation.


### 2.3. M√©thode 2 ‚Äî R√©gression Lasso (L1)

La **r√©gression logistique p√©nalis√©e L1** (ou **Lasso**) fait partie des **m√©thodes embedded** :  
la s√©lection de variables est effectu√©e **pendant** l‚Äôentra√Ænement du mod√®le.

Le principe repose sur l‚Äôajout d‚Äôune **p√©nalisation absolue** sur les coefficients du mod√®le :

`minimize ||y - XŒ≤||¬≤ + Œª Œ£ |Œ≤·µ¢|`


Sous l‚Äôeffet du param√®tre de r√©gularisation `Œª`, certains coefficients `Œ≤·µ¢` deviennent **exactement nuls**, ce qui √©quivaut √† **√©liminer la variable correspondante**.  

Avantages :
- S√©lection automatique des variables les plus explicatives,  
- R√©duction du sur-apprentissage,  
- Maintien d‚Äôune bonne interpr√©tabilit√© du mod√®le lin√©aire.





### 2.4. M√©thode 3 ‚Äî XGBoost 

Le mod√®le **XGBoost (Extreme Gradient Boosting)** est une m√©thode **arborescente** et **it√©rative** fond√©e sur le gradient boosting.  
Il combine de nombreux arbres de d√©cision faibles pour construire un mod√®le global puissant.

Chaque variable se voit attribuer une **importance** mesur√©e par :
- la **fr√©quence d‚Äôutilisation** de la variable dans les arbres,
- la **r√©duction du gain d‚Äôerreur (Gain)** qu‚Äôelle procure lors d‚Äôune division,
- ou la **couverture (Cover)** des √©chantillons concern√©s.

Les importances sont ensuite normalis√©es pour obtenir un **score global** entre 0 et 1.  

Avantages :
- Capte les **interactions non lin√©aires** et **les effets crois√©s** entre variables,  
- Tr√®s robuste aux donn√©es bruit√©es ou corr√©l√©es,  
- Excellente performance empirique.


### 2.5. Pond√©ration et agr√©gation des scores

Chaque m√©thode fournit une **mesure compl√©mentaire de la pertinence** des variables :
- l‚ÄôInformation Mutuelle capture les d√©pendances statistiques,  
- le Lasso privil√©gie les variables lin√©airement discriminantes,  
- XGBoost identifie les contributions non lin√©aires dans un cadre de type arbre.

Pour obtenir une vision plus √©quilibr√©e, les trois scores ont √©t√© **normalis√©s entre 0 et 1** puis combin√©s en un **score global pond√©r√©** :

`Score_global = 0.4 √ó IM + 0.3 √ó Lasso + 0.3 √ó XGBoost`


Les poids ont √©t√© choisis pour donner une **l√©g√®re priorit√© √† la robustesse statistique (IM)**, tout en int√©grant la **s√©lection structurelle (Lasso)** et la **non-lin√©arit√© (XGBoost)**.

Les variables pr√©sentant le plus haut score global ont √©t√© retenues pour constituer la base finale du mod√®le pr√©dictif.



## 3. Mod√©lisation et √©valuation

### 3.1. M√©thodologie d‚Äô√©valuation

La variable cible `readmitted` √©tant fortement **d√©s√©quilibr√©e** (~11 % de r√©admissions), le crit√®re principal choisi est la **PR-AUC (Precision‚ÄìRecall Area Under Curve)**.  
Cette m√©trique √©value la capacit√© du mod√®le √† **identifier les patients r√©admis** (rappel) tout en **limitant les fausses alertes** (pr√©cision).  
Elle est plus adapt√©e qu‚Äôune ROC-AUC dans le cas d‚Äôun d√©s√©quilibre important entre classes.

Crit√®res utilis√©s :
- **PR-AUC** : m√©trique principale.  
- **ROC-AUC** : performance globale de classement.  
- **F1-score** : compromis pr√©cision / rappel au seuil optimal.  
- **Brier Score** : mesure de calibration des probabilit√©s.  
- **Recall@Top 20 %** : taux de vrais positifs dans les 20 % des patients les plus √† risque.

Les donn√©es sont s√©par√©es en **80 % train / 20 % test** (stratifi√©).  
Tous les pr√©traitements (scaling, encodage, s√©lection de variables) sont inclus dans un **pipeline scikit-learn**, assurant l‚Äôabsence de fuite de donn√©es.

---

### 3.2. Mod√®le interpr√©table ‚Äî R√©gression Logistique L1 (Lasso)

Le mod√®le **Logistic Regression L1** a √©t√© choisi pour sa **transparence** et sa capacit√© √† **s√©lectionner automatiquement les variables pertinentes**.  
Il constitue une premi√®re approche interpr√©table et robuste.

**Param√®tres principaux :**
```python
LogisticRegression(
    penalty="l1",
    solver="liblinear",
    class_weight="balanced",
    max_iter=200,
    random_state=42
)
---
### 3.2. Validation crois√©e

**M√©thodologie :**
- **5 folds** : `StratifiedKFold`
- **Scoring** : `{"pr_auc": "average_precision", "roc_auc": "roc_auc"}`

**R√©sultats (validation moyenne ¬± √©cart-type)** :

| Mod√®le      | PR-AUC (¬± std) | ROC-AUC (¬± std) |
|--------------|----------------|-----------------|
| LogReg L1 | 0.197 ¬± 0.005 | 0.638 ¬± 0.007 |
| LogReg L2 | 0.197 ¬± 0.005 | 0.638 ¬± 0.007 |

> ‚úÖ **LogReg L1** retenue pour son caract√®re parcimonieux et interpr√©table.

---

### 3.3. R√©sultats sur jeu de test

| M√©trique | Score |
|-----------|--------|
| **PR-AUC** | 0.193 |
| **ROC-AUC** | 0.633 |
| **F1-score (seuil = 0.49)** | 0.253 |
| **Recall (classe 1)** | 0.529 |
| **Precision (classe 1)** | 0.166 |
| **Brier Score** | 0.232 |

Le seuil a √©t√© d√©termin√© en **maximisant le F1-score**.  
Le mod√®le identifie environ **53 % des patients r√©admis**, au prix d‚Äôun taux mod√©r√© de faux positifs ‚Äî un compromis acceptable en contexte m√©dical.

---

### 3.4. Calibration

Le **Brier score (0.232)** montre une **calibration moyenne** :  
le mod√®le tend √† **sous-estimer les risques** pour les patients √† forte probabilit√© de r√©admission.  
La **courbe de calibration** reste globalement coh√©rente avec la diagonale id√©ale.

<p align="center">
  <img src="outputs/calibration_curve_logreg_l1.png" width="480">
</p>

---

### 3.5. Interpr√©tation du mod√®le

Les coefficients de la **r√©gression logistique L1** permettent une lecture directe de l‚Äôinfluence de chaque variable :

- **Œ≤ > 0** ‚Üí la variable **augmente** la probabilit√© de r√©admission.  
- **Œ≤ < 0** ‚Üí la variable **r√©duit** la probabilit√© de r√©admission.  
- **exp(Œ≤)** = *odds ratio (OR)* : impact multiplicatif sur les chances de r√©admission.

**Exemples d‚Äôinterpr√©tation :**

| Variable | Œ≤ | OR | Interpr√©tation |
|-----------|---|----|----------------|
| `time_in_hospital` | +0.42 | 1.52 | Les s√©jours plus longs augmentent le risque de r√©admission. |
| `num_lab_procedures` | +0.27 | 1.31 | Un nombre √©lev√© d‚Äôexamens traduit une pathologie plus lourde. |
| `age_[0-30)` | ‚àí0.68 | 0.51 | Les patients jeunes pr√©sentent un risque plus faible de r√©admission. |

---

### 3.6. Perspectives

- üîπ Tester des mod√®les **ensemblistes** (*Random Forest*, *XGBoost*) et un **r√©seau de neurones (MLP)** pour mesurer le gain li√© aux non-lin√©arit√©s.  
- üîπ Am√©liorer la **calibration** via *Platt Scaling* ou *Isotonic Regression*.  
- üîπ Int√©grer un **co√ªt clinique diff√©renci√©** pour ajuster le seuil selon le risque acceptable de faux positifs.  
- üîπ D√©ployer un **score de risque interpr√©table** via un tableau de bord (*SHAP*, *Streamlit*, ou *Gradio*) permettant une visualisation claire des facteurs de risque individuels.



